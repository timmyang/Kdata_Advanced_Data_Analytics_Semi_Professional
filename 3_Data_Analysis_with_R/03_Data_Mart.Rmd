---
title: "Part 3: Data Mart"
output: rmarkdown::github_document
---

# Table of Contents

- **Chapter 1 - 데이터 변경 및 요약 (Data Change and Summary)**
  - R reshape를 이용ㅇ한 데이터 마트 개발
  - sqldf를 이용한 데이터 분석
  - plyr을 이용한 데이터 분석
  - 데이터 테이블s

- **Chapter 2 - 데이터 가공 (Data Processing)**
  - Data Exploration
  - 변수 중요도
  - 변수의 구간화
  
- **Chapter 3 - 기초 분석 및 데이터 관리 (Basic Analysis and Data Management)**
  - 데이터 EDA(탐색적 자료 분석)
  - 결측값 인식
  - 결측값 처리 방법
  - R에서 결측값 처리
  - 이상값(Outlier) 인식과 처리
  

# Chapter 1 - 데이터 변경 및 요약 (Data Change and Summary)

## 1. R reshape를 이용한 데이터 마트 개발

#### 가. 데이터 마트

- **데이터 웨어하우스** 와 **사용자 사이의 중간층에 위치** 한 것으로, 하나의 주제 또는 하나의 부서 중심의 데이터 웨어하우스라고 할 수 있다
- 데이터 마트 내 대부분의 데이터는 데이터 웨어하우스로부터 복제되지만, 자체적으로 수집될 수도 있으며, 관계형 데이터 베이스나 다차원 데이터 베이스를 이용하여 구축 한다
- CRM(Customer Relationship Management) 관련 업무 중에서 핵심 - 고객 데이터 마트 구축
- 동일한 데이터 셋을 활용할 경우, 최신 분석기법들을 이용하면 분석가의 역량에서는 분석 효과가 크게 차이가 나지 않기 떄문에 데이터 마트를 어떻게 구축하느냐에 따라 분석 효과는 크게 차이 난다

최상위

- **전산소:** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ DBA \ \ \ \ \ DBA \ \ \ \ \ DBA \ \ \ \ \ DBA \ \ \ \ \ DBA
- **운영 데이터:** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ RDB \ \ \ \ \ \ \ \ \ \ \ RDB \ \ \ \ \ \ \ \ \ \ 외부DB
- **데이터 변환:** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 접속 \ \ \ 발췌 \ \ \ 필터링 \ \ \ 요약 \ \ \ 정렬
- **데이터 웨어하우스:** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ RDB
- **복사 및 보급:**
- **데이터 마트:** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 지역 \ \ \ 고객 \ \ \ 마케팅 \ \ \ 재무 \ \ \ 협력사
- **데이터 마이닝:** \ \ \ \ \ \ \ \ \ \ 통계분석 클러스터링 신경망 규칙추론 의사결정트리
- **데이터 액세스 툴:** 다차원분석 데이터시각화 EIS/DSS 스프레드시트 응용개발툴
- **최종 사용자:** \ \ \ \ 파워유저 \ \ \ \ 분석가 \ \ \ \ \ \ \ \ \ \ \ \ \ 임원 \ \ \ \ \ \ \ \ \ \ \ \ 고객상담자 \ \ \ \ 응용서버

최하위

#### 나. 요약변수

- 수집된 정보를 **분석에 맞게 종합한 변수** 이다
- 데이터마트에서 가장 기본적인 변수로 **총구매 금액, 금액, 횟수, 구매여부 등 데이터 분석을 위해 만들어 지는 변수** 이다
- 많은 모델을 공통으로 사용될 수 있어 **재활용성이 높다**
- 합계, 횟수와 같이 간단한 구조이므로 자동화하여 상황에 맞게 또는 일반적인 자동화프로그램으로 구축 가능하다
- 요약변수의 단점은 얼마 이상이면 구매하더라도 기준값의 의미 해석이 애매할 수 있다. 이러한 경우, 연속형 변수를 그룹핑해 사용하는 것이 좋다
- <예시>
- **기간별 구매 금액, 횟수 여부**
  - 고객의 구매 패턴을 볼 수 있는 변수이다
- **위클리 쇼퍼**
  - 구매 시기를 통해 고객의 특성을 추정하는데 활용 가능하다
- **상품별 구매 금액, 회수 여부**
  - 고객의 라이프 스테이지와 라이프 스타일 등을 이해하는데 크게 도움이 된다
- **상품별 구매 순서**
  - 고객에 대한 이해와 해석력을 높일 수 있다
- **유통 채널별 구매 금액**
  - 온라인과 오프라인 사용 고객에게 모두 사용하도록 유도하는데 활용한다
- **단어 빈도**
  - 텍스트 자료에서 단어들의 출현 빈도를 데이터화하여 사용한다
- **초기 행동변수**
  - 고객 가입 또는 첫 거래 초기 1개월 간 거래 패턴에 대한 변수로 1년후에 어떤 행동을 보일지를 평가하는 지표로 활용한다
- **트렌드 변수**
  - 추이(상황변화)값을 나타내는 변수이다
- **결측값과 이상값 처리**
  - 결측값과 이상값은 무리해서 처리하려고 하면 시간과 위험이 커질 수 있으므로 데이터의 내용을 파악하여 처리해야 한다
- **연속형 변수의 구간화**
  - 분석후 적용 단계를 고려한 데이터 분석을 위해 연령이나 비용 등 연속형 변수를 구간화 하는 것이 필요하다. 반드시 10, 100, 1000 단위로 구간화하지 말고 의미있는 구간으로 구간화한다


#### 다. 파생변수

- 사용자(분석가)가 **특정 조건을 만족** 하거나 **특정 함수에 의해 값을 만들어 의미를 부여한 변수** 이다
- 매우 **주관적일 수 있으므로 논리적 타당성을 갖추어 개발** 해야 한다
- **세분화, 고객 행동 예측, 캠페인 반응 예측** 에 매우 잘 활용된다
- 파생변수는 상황에 따라 특정 상황에만 유의미하지 않게 대표성을 나타나게 할 필요가 있다
- <예시>
- **근무시간 구매지수**
  - 근무시간대에 거래가 발생하는 비율을 산출하여 활용
- **주 구매 매장 변수**
  - 고객의 주거래 매장을 예측하여 적절한 분석에 활용
- **주 활동 지역 변수**
  - 고객의 정보나 거래내용을 통해 주 활동지역을 예측하여 분석에 활용
- **주 구매상품 변수**
  - 상품을 추천하는데 활용
  - (1순위 상품을 구매하고 2순위 상품을 구매하지 않은 고객에게 추천)
- **구매상품 다양성 변수**
  - 고객이 다양한 상품이나 같은 브랜드 등을 구매하는 성향을 파악하여 분석에 필요한 변수로 변환
- **선호하는 가격대 변수**
  - 각자의 취향, 소득, 서비스 등에 따라 많이 투자하는 상품군이 있는데 주로 패션 분야에 중요하게 적용
- **시즌 선호고객 변수**
  - 각자 의미 있게 생각하는 날 소비가 많이 이루어지기 때문에 패턴을 파악하여 분석에 활용(주로 유통업)
- **라이프 스테이지 변수**
  - 고객이 속한 라이프 스테이지를 예측하여 행동을 이해하고 그들의 니즈와 가치를 파악하는데 활용
- **라이프스타일 변수**
  - 고객의 라이프스타일을 보고 상품구매를 유도하는데 활용
- **행사민감 변수**
  - 같은 상품도 행사를 할 때 구매하는 사람이 있고 행사와 관련 없이 구매하는 사람이 있는데 이런 행동 패턴을 파악하여 활용
- **휴면가망 변수**
  - 고객은 늘 구매하지 않기 떄문에 고객의 취향이나 관심사가 변해 구매하지 않거나 경쟁사의 상품을 선호하게 되는 경우가 있는데 이를 파악하여 사전 대응에 활용
- **최대가치 변수**
  - 고객의 가치를 판단하여 어느 정도를 판매할 수 있는지를 예측하는데 활용
- **최적 통화 시간**
  - 콜센터에 걸려온 시간으로 고객의 직업 등을 고려한 통화시간을 예측하여 통화를 시도

#### 라. reshape의 활용

```{r}
# install.packages("reshape")
# packageVersion("reshape")
library(reshape)
```

- reshape 패키지에는 **melt()와 cast()** 라는 2개의 핵심 함수가 있다 (철을 녹이고 다시 틀에 넣어 모양을 만드는 과정에 비유하여, **녹이는 함수를 melt(), 모양을 만드는 함수를 cast()** 로 사용한다)
- **melt():** 원데이터 형태로 만드는 함수
- **cast():** 요약 형태로 만드는 함수
- 다음의 예시는 reshape 패키지의 주요 기능인 melt를 이용해 airquality 데이터의 Month, id를 기준으로 모든 데이터를 표준형식으로 변환한다
- 변수를 조합해 변수명을 만들고 변수들을 시간, 상품 등의 차원에 결합해 다양한 요약변수와 파생변수를 쉽게 생성하여 데이터마트를 구성할 수 있게 한다



```{r}
str(airquality)
head(airquality)
summary(airquality)
```

- **melt() 함수**
  - Melt an object into a form suitable for easy casting

```{r}
str(melt)

m <- melt(airquality, id = c("Month", "Day"), na.rm = T)
head(m)
```

- **cast() 함수**
  - Cast a molten data frame into the reshaped or aggregarted form you want

```{r}
str(cast)

head(cast(m, Day ~ Month ~ variable))
```

With aggregation
```{r}
cast(m, Month ~ variable, mean)

head(cast(m, Day ~ variable, mean))

b <- cast(m, Month ~ Day, mean)
b[, 1:9]
```

Without aggregation

```{r}
head(cast(m, Month + Day ~ variable))

a <- cast(m, Month + variable ~ Day)
a[ , 1:10]

b <- cast(m, Month ~ variable + Day)
b[ , 1:10]
```


**기출문제**  
**57. 다음 중 방대한 조직 내에서 분산 운영되는 각각의 데이터베이스 관리시스템을 효율적으로 통합하여 조정, 관리하는 실무적인 활용 방법은 무엇인가?**

1. 데이터 웨어하우스  
2. OLAP  
3. 데이터 마트  
4. BI

(정답): 1번  
(해설): **데이터 웨어하우스** 는 정보(data)와 창고(warehouse)의 합성어로 데이터베이스 시스템에서 의사결정에 필요한 데이터를 미리 추출하여, 이를 원하는 형태로 변환하고 통합한 읽기 전용의 데이터 저장소다. **데이터 웨어하우스** 는 데이터베이스 시스템 하나를 대상으로 할 수도 있고 여러 개를 대상으로 할 수도 있다

**58. 고객 데이터 마트에서 가장 기본적인 변수로, 고객-상품-채널을 종합(Aggregation)한 변수를 무엇이라고 하는가?**

(정답): 요약변수

**59-1. 파생변수는 사용자가 특정 조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여한 변수이다. 다음 중 파생변수의 설명으로 적절한 것은?**

1. 파생변수는 매우 주관적인 변수이므로 논리적 타당성을 갖춰야 한다  
2. 파생변수는 많은 모델에서 공통적으로 많이 사용될 수 있다  
3. 파생변수는 재활용성이 높다  
4. 파생변수는 다양한 모델을 개발해야 하는 경우, 효율적으로 사용할 수 있다

(정답): 1번

## 2. sqldf를 이용한 데이터 분석

```{r warning = FALSE}
# install.packages("sqldf")
# packageVersion("sqldf")
library(sqldf)
library(RSQLite)
```

- sqldf는 R에서 sql의 명령어를 사용 가능하게 해주는 패키지이다
- SAS에서의 proc sql와 같은 역할을 하는 패키지이다
- <예시1>
- **SQL:** SELECT * FROM [Data frame]
  - **R:** sqldf("SELECT * FROM [Data frame]")
- **SQL:** SELECT * FROM [Data frame] **numrows** 10
  - **R:** sqldf("SELECT * FROM [Data frame] **limit** 10)
- **SQL:** SELECT * FROM [Data frame] WHERE [col] **=** 'char%'
  - **R:** sqldf("SELECT * FROM [Data frame] WHERE [col] **like** 'char%' ")
- <예시2>
- **head([df])**
  - sqldf("SELECT * FROM [df] limit 6")
- **subset([df], grep1("qn%, [col]))**
  - sqldf("SELECT * FROM [df] WHERe [col] like 'qn%' ")
- **subset([df], [col] %in% c("BF", "HF"))**
  - sqldf("SELECT * FROM [df] WHERE [col] in("BF", "HF")")
- **rbind([df1], [df2])**
  - sqldf("SELECT * FROM [df1] UNION ALL SELECT * FROM [df2]")
- **merge([df1], [df2])**
  - sqldf("SELECT * FROM [df1], [df2]")
- **df[order([df]$[col], decreasing = T), ]**
  - sqldf("SELECT * FROM [df] ORDER BY [col] desc")
- <예시3>
```{r}
str(iris)

sqldf("SELECT * FROM iris limit 6")
```

**기출문제**  
**61-1. 다음 중 데이터베이스와 통신을 위해 고안된 언어는 무엇인가?**

1. JAVA  
2. R  
3. Python  
4. SQL

(정답): 4번


## 3. plyr을 이용한 데이터 분석

```{r}
# install.packages("plyr")
# packageVersion("plyr")
library(plyr)
```

- plyr은 apply 함수에 기반해 데이터 출력변수를 동시에 배열로 치환하여 처리하는 패키지이다
- split-apply-combine: 데이터를 분리하고 처리한 다음, 다시 결합하는 등 필수적인 데이터 처리 기능을 제공한다

\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ **array** \ \ \ \ \ **data frame** \ \ \ \ \ **list** \ \ \ \ \ **nothing**  
**Array** \ \ \ \ \ \ \ \ \ \ \ \ aaply \ \ \ \ \ adply \ \ \ \ \ \ \ \ \ \ \ \ \ \ alply \ \ \ \ \ \ a_ply  
**Data frame** \ \ daply \ \ \ \ \ ddply \ \ \ \ \ \ \ \ \ \ \ \ \ \ dlply \ \ \ \ \ \ d_ply  
**List** \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ laply \ \ \ \ \ \ ldply \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ llply \ \ \ \ \ \ \  l_ply  
**N replicates** \ raply \ \ \ \ \ rdply \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rlply \ \ \ \ \ \ \ r_ply  
**Function** \ \ \ \ \ \ maply \ \ \ \ mdply \ \ \ \ \ \ \ \ \ \ \ \ \ mlply \ \ \ \ \ m_ply  
**arguments**

- test data 불러오기
```{r}
test.data <- data.frame(year = c(rep(2011, 5), rep(2012, 5)), value = c(31, 84, 66, 31, 84, 95, 83, 91, 95, 83))
test.data
```

- test.data를 이용하여 sd와 mean의 비율인 변동계수 CV(Coefficient of Variation)를 산출
```{r}
str(ddply)

dd.test <- ddply(test.data, "year", function(x) {
  m.value <- mean(x$value)
  sd.value <- sd(x$value)
  cv <- round(sd.value / m.value, 4)
  data.frame(cv.value = cv)
})

dd.test
```

**기출문제**  
**63. Chickwts 데이터프레임은 여섯 가지 종류의 닭 사료 첨가물(feed)과 각 사료를 먹인 닭의 무게 (weight)를 변수로 가진다. 아래의 (1)의 기초통계량과 각 feed별 weight의 평균을 계산하여, 아래 (2)와 같은 결과물을 만들기 위한 코드로 다음 중 가장 적절한 것은?**

1. ddply(chickwts, ~feed, groupmean = mean(weight))  
2. **ddply(chickwts, ~feed, summarize, groupmean = mean(weight))**

## 4. 데이터 테이블 (data.table)

```{r}
# install.packages("data.table")
# packageVersion("data.table")
library(data.table)
```

- data.table 패키지는 R에서 **가장 많이 사용하는 데이터 핸들링 패키지** 중 하나이다
- data.table은 큰 데이터를 **탐색, 연산, 병합 하는데 아주 유용** 하다
- 기존 data.frame 방식보다 **월등히 빠른 속도** 이다
- 특정 column을 key 값으로 색인을 지정한 후 데이터를 처리한다
- **빠른 grouping과 ordering, 짧은 문장 지원 측면에서 데이터프레임보다 유용** 하다(*속도차 큼*)

```{r}
DF <- data.frame(x = runif(2.6e+07), y = rep(LETTERS, each = 10000))
df <- data.frame(x = runif(2.6e+07), y = rep(letters, each = 10000))

system.time(x <- DF[DF$y == "C", ])

DT <- as.data.table(DF)
setkey(DT, y)
system.time(x <- DT[J("C"), ])
```

**기출문제**  
**64. R에서 제공하는 데이터 가공, 처리를 위한 패키지의 설명으로 가장 부적절한 것은?**

1. **data.table 패키지는 데이터 프레임 처리함수인 ddply 함수를 제공한다**  
2. reshape 패키지는 melt와 cast를 이용하여 데이터를 재구성할 수 있다  
3. sqldf 패키지는 R에서 표준 SQL 명령을 실행하고 결과를 가져올 수 있다  
4. plyr 패키지는 데이터의 분리, 결합 등 필수적인 데이터 처리기능을 제공한다


# Chapter 2 - 데이터 가공 (Data Processing)

## 1. Data Exploration

## 2. 변수 중요도

## 3. 변수의 구간화
  
  
# Chapter 3 - 기초 분석 및 데이터 관리 (Basic Analysis and Data Management)

## 1. 데이터 EDA(탐색적 자료 분석)

## 2. 결측값 인식

## 3. 결측값 처리 방법

## 4. R에서 결측값 처리

## 5. 이상값(Outlier) 인식과 처리